{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-04-19T14:39:36.207171Z","iopub.status.busy":"2023-04-19T14:39:36.206419Z","iopub.status.idle":"2023-04-19T14:39:56.030119Z","shell.execute_reply":"2023-04-19T14:39:56.028633Z","shell.execute_reply.started":"2023-04-19T14:39:36.207128Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorflow in /opt/conda/lib/python3.7/site-packages (2.11.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.29.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.51.1)\n","Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from tensorflow) (59.8.0)\n","Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.8.0)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from tensorflow) (23.0)\n","Requirement already satisfied: keras<2.12,>=2.11.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.11.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (4.4.0)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.4.0)\n","Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.11.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (23.1.21)\n","Requirement already satisfied: tensorboard<2.12,>=2.11 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.11.2)\n","Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.2.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.2.0)\n","Collecting protobuf<3.20,>=3.9.2\n","  Downloading protobuf-3.19.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (15.0.6.1)\n","Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.21.6)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n","Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.28.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.35.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n","Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.2.3)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (4.11.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.1.1)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.26.14)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow) (2.1.1)\n","Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.11.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\n","Installing collected packages: protobuf\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.20.3\n","    Uninstalling protobuf-3.20.3:\n","      Successfully uninstalled protobuf-3.20.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf 21.12.2 requires cupy-cuda115, which is not installed.\n","tfx-bsl 1.12.0 requires google-api-python-client<2,>=1.7.11, but you have google-api-python-client 2.83.0 which is incompatible.\n","tfx-bsl 1.12.0 requires pyarrow<7,>=6, but you have pyarrow 5.0.0 which is incompatible.\n","tensorflow-transform 1.12.0 requires pyarrow<7,>=6, but you have pyarrow 5.0.0 which is incompatible.\n","onnx 1.13.1 requires protobuf<4,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n","apache-beam 2.44.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.6 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed protobuf-3.19.6\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install tensorflow"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-04-19T14:39:56.034319Z","iopub.status.busy":"2023-04-19T14:39:56.033859Z","iopub.status.idle":"2023-04-19T14:40:02.290260Z","shell.execute_reply":"2023-04-19T14:40:02.289159Z","shell.execute_reply.started":"2023-04-19T14:39:56.034263Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from keras.applications.mobilenet import MobileNet, preprocess_input\n","from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dropout, Dense,BatchNormalization, Flatten, MaxPool2D\n","from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n","from keras.layers import Conv2D, Reshape\n","from tensorflow.keras.utils import Sequence\n","from keras.backend import epsilon\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.layers import GlobalAveragePooling2D\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import cv2\n","\n","from tqdm.notebook import tqdm_notebook as tqdm\n","\n","import os"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-04-19T14:40:02.292876Z","iopub.status.busy":"2023-04-19T14:40:02.291760Z","iopub.status.idle":"2023-04-19T14:40:03.124658Z","shell.execute_reply":"2023-04-19T14:40:03.123614Z","shell.execute_reply.started":"2023-04-19T14:40:02.292834Z"},"trusted":true},"outputs":[],"source":["angry= '../input/dog-emotions-prediction/images/angry/'\n","sad = '../input/dog-emotions-prediction/images/sad/'\n","relaxed = '../input/dog-emotions-prediction/images/relaxed/'\n","happy = '../input/dog-emotions-prediction/images/happy/'\n","\n","\n","angry_path = os.listdir(angry)\n","sad_path = os.listdir(sad)\n","relaxed_path = os.listdir(relaxed)\n","happy_path = os.listdir(happy)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-04-19T14:40:03.128320Z","iopub.status.busy":"2023-04-19T14:40:03.127635Z","iopub.status.idle":"2023-04-19T14:40:03.134140Z","shell.execute_reply":"2023-04-19T14:40:03.133030Z","shell.execute_reply.started":"2023-04-19T14:40:03.128279Z"},"trusted":true},"outputs":[],"source":["def load_img(path):\n","    image = cv2.imread(path)\n","    image = cv2.resize(image,(224, 224))\n","    return image[...,::-1]"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-04-19T14:40:03.136329Z","iopub.status.busy":"2023-04-19T14:40:03.135678Z","iopub.status.idle":"2023-04-19T14:40:03.142959Z","shell.execute_reply":"2023-04-19T14:40:03.141966Z","shell.execute_reply.started":"2023-04-19T14:40:03.136292Z"},"trusted":true},"outputs":[],"source":["dataset_path = \"/kaggle/input/dog-emotions-prediction/images\""]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-04-19T14:40:03.145375Z","iopub.status.busy":"2023-04-19T14:40:03.144544Z","iopub.status.idle":"2023-04-19T14:40:03.151717Z","shell.execute_reply":"2023-04-19T14:40:03.150728Z","shell.execute_reply.started":"2023-04-19T14:40:03.145335Z"},"trusted":true},"outputs":[],"source":["data_with_aug = ImageDataGenerator(horizontal_flip=True,\n","                                   vertical_flip=False,\n","                                   rescale=1./255,\n","                                  validation_split=0.3)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-04-19T14:40:03.154096Z","iopub.status.busy":"2023-04-19T14:40:03.153296Z","iopub.status.idle":"2023-04-19T14:40:07.794068Z","shell.execute_reply":"2023-04-19T14:40:07.792754Z","shell.execute_reply.started":"2023-04-19T14:40:03.154059Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 11147 images belonging to 4 classes.\n"]}],"source":["train = data_with_aug.flow_from_directory(dataset_path,\n","                                          class_mode=\"binary\",\n","                                          target_size=(96, 96),\n","                                          batch_size=32,\n","                                          subset=\"training\")"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-04-19T14:40:07.796526Z","iopub.status.busy":"2023-04-19T14:40:07.795638Z","iopub.status.idle":"2023-04-19T14:40:08.940847Z","shell.execute_reply":"2023-04-19T14:40:08.939820Z","shell.execute_reply.started":"2023-04-19T14:40:07.796465Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 4774 images belonging to 4 classes.\n"]}],"source":["val = data_with_aug.flow_from_directory(dataset_path,\n","                                          class_mode=\"binary\",\n","                                          target_size=(96, 96),\n","                                          batch_size=32,\n","                                          subset=\"validation\"\n","                                          )"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-04-19T14:40:08.942943Z","iopub.status.busy":"2023-04-19T14:40:08.942519Z","iopub.status.idle":"2023-04-19T14:40:14.228952Z","shell.execute_reply":"2023-04-19T14:40:14.227854Z","shell.execute_reply.started":"2023-04-19T14:40:08.942899Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_96_no_top.h5\n","9406464/9406464 [==============================] - 1s 0us/step\n"]}],"source":["mnet = MobileNetV2(include_top = False, weights = \"imagenet\" ,input_shape=(96,96,3))"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-04-19T14:40:14.232813Z","iopub.status.busy":"2023-04-19T14:40:14.232424Z","iopub.status.idle":"2023-04-19T14:40:14.755116Z","shell.execute_reply":"2023-04-19T14:40:14.754043Z","shell.execute_reply.started":"2023-04-19T14:40:14.232773Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," mobilenetv2_1.00_96 (Functi  (None, 3, 3, 1280)       2257984   \n"," onal)                                                           \n","                                                                 \n"," global_average_pooling2d (G  (None, 1280)             0         \n"," lobalAveragePooling2D)                                          \n","                                                                 \n"," dense (Dense)               (None, 512)               655872    \n","                                                                 \n"," batch_normalization (BatchN  (None, 512)              2048      \n"," ormalization)                                                   \n","                                                                 \n"," dropout (Dropout)           (None, 512)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 128)               65664     \n","                                                                 \n"," dropout_1 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_2 (Dense)             (None, 4)                 516       \n","                                                                 \n","=================================================================\n","Total params: 2,982,084\n","Trainable params: 723,076\n","Non-trainable params: 2,259,008\n","_________________________________________________________________\n"]}],"source":["tf.keras.backend.clear_session()\n","\n","model = Sequential([mnet,\n","                    GlobalAveragePooling2D(),\n","                    Dense(512, activation = \"relu\"),\n","                    BatchNormalization(),\n","                    Dropout(0.3),\n","                    Dense(128, activation = \"relu\"),\n","                    Dropout(0.1),\n","                    # Dense(32, activation = \"relu\"),\n","                    # Dropout(0.3),\n","                    Dense(4, activation = \"sigmoid\")])\n","\n","model.layers[0].trainable = False\n","\n","model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=\"accuracy\")\n","\n","model.summary()\n","Model: \"sequential\""]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-04-19T14:40:14.756883Z","iopub.status.busy":"2023-04-19T14:40:14.756516Z","iopub.status.idle":"2023-04-19T14:40:14.763832Z","shell.execute_reply":"2023-04-19T14:40:14.762631Z","shell.execute_reply.started":"2023-04-19T14:40:14.756844Z"},"trusted":true},"outputs":[],"source":["def scheduler(epoch):\n","    if epoch <= 2:\n","        return 0.001\n","    elif epoch > 2 and epoch <= 15:\n","        return 0.0001 \n","    else:\n","        return 0.00001\n","\n","lr_callbacks = tf.keras.callbacks.LearningRateScheduler(scheduler)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-04-19T14:40:14.766389Z","iopub.status.busy":"2023-04-19T14:40:14.765641Z","iopub.status.idle":"2023-04-19T15:16:17.744693Z","shell.execute_reply":"2023-04-19T15:16:17.743725Z","shell.execute_reply.started":"2023-04-19T14:40:14.766348Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  after removing the cwd from sys.path.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/40\n","349/349 [==============================] - 91s 237ms/step - loss: 1.4021 - accuracy: 0.4305 - val_loss: 1.2540 - val_accuracy: 0.4715 - lr: 0.0010\n","Epoch 2/40\n","349/349 [==============================] - 52s 149ms/step - loss: 1.1376 - accuracy: 0.5102 - val_loss: 1.2118 - val_accuracy: 0.4757 - lr: 0.0010\n","Epoch 3/40\n","349/349 [==============================] - 52s 148ms/step - loss: 1.0638 - accuracy: 0.5477 - val_loss: 1.2046 - val_accuracy: 0.4897 - lr: 0.0010\n","Epoch 4/40\n","349/349 [==============================] - 50s 144ms/step - loss: 0.9399 - accuracy: 0.6122 - val_loss: 1.1934 - val_accuracy: 0.4914 - lr: 1.0000e-04\n","Epoch 5/40\n","349/349 [==============================] - 51s 146ms/step - loss: 0.9085 - accuracy: 0.6266 - val_loss: 1.1935 - val_accuracy: 0.4981 - lr: 1.0000e-04\n","Epoch 6/40\n","349/349 [==============================] - 50s 142ms/step - loss: 0.8726 - accuracy: 0.6518 - val_loss: 1.2086 - val_accuracy: 0.5021 - lr: 1.0000e-04\n","Epoch 7/40\n","349/349 [==============================] - 50s 144ms/step - loss: 0.8486 - accuracy: 0.6627 - val_loss: 1.2153 - val_accuracy: 0.5004 - lr: 1.0000e-04\n","Epoch 8/40\n","349/349 [==============================] - 50s 143ms/step - loss: 0.8104 - accuracy: 0.6810 - val_loss: 1.2276 - val_accuracy: 0.4948 - lr: 1.0000e-04\n","Epoch 9/40\n","349/349 [==============================] - 50s 144ms/step - loss: 0.7862 - accuracy: 0.6915 - val_loss: 1.2568 - val_accuracy: 0.4902 - lr: 1.0000e-04\n","Epoch 10/40\n","349/349 [==============================] - 50s 143ms/step - loss: 0.7603 - accuracy: 0.7017 - val_loss: 1.2747 - val_accuracy: 0.4870 - lr: 1.0000e-04\n","Epoch 11/40\n","349/349 [==============================] - 50s 143ms/step - loss: 0.7355 - accuracy: 0.7125 - val_loss: 1.2864 - val_accuracy: 0.4876 - lr: 1.0000e-04\n","Epoch 12/40\n","349/349 [==============================] - 50s 144ms/step - loss: 0.7042 - accuracy: 0.7272 - val_loss: 1.3063 - val_accuracy: 0.4849 - lr: 1.0000e-04\n","Epoch 13/40\n","349/349 [==============================] - 50s 143ms/step - loss: 0.6793 - accuracy: 0.7359 - val_loss: 1.3263 - val_accuracy: 0.4811 - lr: 1.0000e-04\n","Epoch 14/40\n","349/349 [==============================] - 50s 144ms/step - loss: 0.6442 - accuracy: 0.7564 - val_loss: 1.3548 - val_accuracy: 0.4721 - lr: 1.0000e-04\n","Epoch 15/40\n","349/349 [==============================] - 51s 147ms/step - loss: 0.6193 - accuracy: 0.7644 - val_loss: 1.3715 - val_accuracy: 0.4744 - lr: 1.0000e-04\n","Epoch 16/40\n","349/349 [==============================] - 75s 215ms/step - loss: 0.5922 - accuracy: 0.7735 - val_loss: 1.4091 - val_accuracy: 0.4736 - lr: 1.0000e-04\n","Epoch 17/40\n","349/349 [==============================] - 56s 161ms/step - loss: 0.5494 - accuracy: 0.7981 - val_loss: 1.4021 - val_accuracy: 0.4801 - lr: 1.0000e-05\n","Epoch 18/40\n","349/349 [==============================] - 62s 179ms/step - loss: 0.5444 - accuracy: 0.7997 - val_loss: 1.4013 - val_accuracy: 0.4782 - lr: 1.0000e-05\n","Epoch 19/40\n","349/349 [==============================] - 59s 170ms/step - loss: 0.5416 - accuracy: 0.8036 - val_loss: 1.4097 - val_accuracy: 0.4772 - lr: 1.0000e-05\n","Epoch 20/40\n","349/349 [==============================] - 51s 146ms/step - loss: 0.5392 - accuracy: 0.8016 - val_loss: 1.4173 - val_accuracy: 0.4786 - lr: 1.0000e-05\n","Epoch 21/40\n","349/349 [==============================] - 57s 163ms/step - loss: 0.5315 - accuracy: 0.8034 - val_loss: 1.4080 - val_accuracy: 0.4801 - lr: 1.0000e-05\n","Epoch 22/40\n","349/349 [==============================] - 50s 142ms/step - loss: 0.5279 - accuracy: 0.8075 - val_loss: 1.4186 - val_accuracy: 0.4736 - lr: 1.0000e-05\n","Epoch 23/40\n","349/349 [==============================] - 50s 143ms/step - loss: 0.5286 - accuracy: 0.8096 - val_loss: 1.4184 - val_accuracy: 0.4761 - lr: 1.0000e-05\n","Epoch 24/40\n","349/349 [==============================] - 56s 160ms/step - loss: 0.5108 - accuracy: 0.8159 - val_loss: 1.4358 - val_accuracy: 0.4717 - lr: 1.0000e-05\n","Epoch 25/40\n","349/349 [==============================] - 50s 142ms/step - loss: 0.5138 - accuracy: 0.8153 - val_loss: 1.4303 - val_accuracy: 0.4797 - lr: 1.0000e-05\n","Epoch 26/40\n","349/349 [==============================] - 50s 145ms/step - loss: 0.5088 - accuracy: 0.8195 - val_loss: 1.4430 - val_accuracy: 0.4698 - lr: 1.0000e-05\n","Epoch 27/40\n","349/349 [==============================] - 50s 143ms/step - loss: 0.5118 - accuracy: 0.8130 - val_loss: 1.4264 - val_accuracy: 0.4751 - lr: 1.0000e-05\n","Epoch 28/40\n","349/349 [==============================] - 51s 146ms/step - loss: 0.5078 - accuracy: 0.8179 - val_loss: 1.4381 - val_accuracy: 0.4736 - lr: 1.0000e-05\n","Epoch 29/40\n","349/349 [==============================] - 51s 145ms/step - loss: 0.5092 - accuracy: 0.8155 - val_loss: 1.4414 - val_accuracy: 0.4742 - lr: 1.0000e-05\n","Epoch 30/40\n","349/349 [==============================] - 52s 150ms/step - loss: 0.4995 - accuracy: 0.8178 - val_loss: 1.4473 - val_accuracy: 0.4721 - lr: 1.0000e-05\n","Epoch 31/40\n","349/349 [==============================] - 53s 152ms/step - loss: 0.4900 - accuracy: 0.8211 - val_loss: 1.4605 - val_accuracy: 0.4700 - lr: 1.0000e-05\n","Epoch 32/40\n","349/349 [==============================] - 56s 162ms/step - loss: 0.4987 - accuracy: 0.8205 - val_loss: 1.4538 - val_accuracy: 0.4728 - lr: 1.0000e-05\n","Epoch 33/40\n","349/349 [==============================] - 50s 143ms/step - loss: 0.4877 - accuracy: 0.8267 - val_loss: 1.4615 - val_accuracy: 0.4700 - lr: 1.0000e-05\n","Epoch 34/40\n","349/349 [==============================] - 50s 144ms/step - loss: 0.4817 - accuracy: 0.8277 - val_loss: 1.4652 - val_accuracy: 0.4726 - lr: 1.0000e-05\n","Epoch 35/40\n","349/349 [==============================] - 51s 145ms/step - loss: 0.4836 - accuracy: 0.8236 - val_loss: 1.4649 - val_accuracy: 0.4688 - lr: 1.0000e-05\n","Epoch 36/40\n","349/349 [==============================] - 52s 149ms/step - loss: 0.4849 - accuracy: 0.8245 - val_loss: 1.4647 - val_accuracy: 0.4711 - lr: 1.0000e-05\n","Epoch 37/40\n","349/349 [==============================] - 51s 145ms/step - loss: 0.4781 - accuracy: 0.8306 - val_loss: 1.4731 - val_accuracy: 0.4707 - lr: 1.0000e-05\n","Epoch 38/40\n","349/349 [==============================] - 51s 145ms/step - loss: 0.4862 - accuracy: 0.8247 - val_loss: 1.4723 - val_accuracy: 0.4705 - lr: 1.0000e-05\n","Epoch 39/40\n","349/349 [==============================] - 50s 144ms/step - loss: 0.4719 - accuracy: 0.8328 - val_loss: 1.4816 - val_accuracy: 0.4684 - lr: 1.0000e-05\n","Epoch 40/40\n","349/349 [==============================] - 50s 143ms/step - loss: 0.4659 - accuracy: 0.8343 - val_loss: 1.4785 - val_accuracy: 0.4776 - lr: 1.0000e-05\n"]}],"source":["hist = model.fit_generator(train,\n","                    epochs=40,\n","                    callbacks=[lr_callbacks],\n","                    validation_data=val)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["img_path = '/kaggle/input/dog-emotions-prediction/images/relaxed/10011399856_62324e2bd2_b.jpg'\n","img = cv2.imread(img_path)\n","img = cv2.resize(img, (96, 96))\n","img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Convert from BGR to RGB\n","img = img / 255.0 # Normalize the image\n","\n","# Reshape the image to have a batch size of 1\n","img = np.reshape(img, (1, 96, 96, 3))\n","\n","# Make the prediction\n","predictions = model.predict(img)\n","\n","# Print the predicted class\n","class_names = ['angry', 'happy', 'relaxed', 'sad']\n","predicted_class = np.argmax(predictions)\n","print(\"Predicted class:\", class_names[predicted_class])"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
